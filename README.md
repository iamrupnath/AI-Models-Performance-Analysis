
# ğŸ“Š AI Models Performance Analysis

### A Data-Driven Comparison of Intelligence, Cost, Speed, and Usability

---

## ğŸ“Œ Project Overview

Choosing the right AI language model is no longer about intelligence alone.
Modern models vary widely in **cost, speed, latency, and context capacity**, making selection a multi-dimensional decision.

This project delivers a **complete end-to-end data analytics analysis** comparing modern AI language models across key performance and business metrics to support **informed, use-case-driven decisions**.

The project is **purely analytical** â€” no machine learning, no black-box modeling.

---

## ğŸ¯ Objectives

* Compare AI models across **intelligence, price, speed, latency, and context window**
* Identify **high-value and cost-efficient models**
* Understand **speed vs latency trade-offs**
* Evaluate **creator-level strategies**
* Map models to **real-world use cases**
* Build **clear, decision-ready dashboards**

---

## ğŸ—‚ Dataset Description

Each row represents a **unique AI language model**.

### Key Columns:

* `Model` â€“ Model name
* `Creator` â€“ Organization / vendor
* `Context_Window_Tokens` â€“ Maximum token capacity
* `Intelligence_Index` â€“ Relative intelligence score
* `Price_USD_per_1M` â€“ Cost per 1M tokens
* `Speed (median token/s)` â€“ Throughput
* `Latency (First Answer Chunk /s)` â€“ Initial response delay

---

## ğŸ›  Tools & Technologies

* **Python**
* **NumPy**
* **Pandas**
* **Matplotlib**

âŒ No Seaborn
âŒ No Machine Learning

---

## ğŸ” Analysis Workflow

### 1ï¸âƒ£ Data Cleaning & Preparation

* Numeric conversion & validation
* Handling missing / invalid values
* Context window normalization
* Feature engineering (e.g., Intelligence per Dollar)

---

### 2ï¸âƒ£ Exploratory Data Analysis (EDA)

#### âœ” Creator-Level Analysis

* No single creator dominates all metrics
* Vendors follow distinct optimization strategies

#### âœ” Intelligence vs Price

* Intelligence does **not scale linearly** with price
* Clear **diminishing returns** at higher cost tiers

#### âœ” Speed vs Latency

* Speed and latency are **not the same**
* Fast models can still feel slow to users

#### âœ” Context Window Analysis

* Large context windows increase cost
* Context size â‰  intelligence

#### âœ” Balanced Models

* Models strong across all dimensions are **rare**
* Trade-offs are unavoidable

---

## ğŸ“Š Dashboards & Visualizations

All dashboards were created using **Matplotlib only**, following clean visualization principles.

### Key Dashboards:

* Creator-level performance comparison
* Intelligence vs Price (segmented & ranked)
* Speed vs Latency (ranked horizontal bars)
* Top models by context window
* Balanced model identification
* Use-case-driven model distribution

Each chart is:

* Properly aligned
* Fully labeled
* Value-annotated
* Portfolio & interview ready

---

## ğŸ‘¥ Use-Case Mapping

| User Type                      | Recommended Model Traits         |
| ------------------------------ | -------------------------------- |
| Data Scientists / ML Engineers | High intelligence, large context |
| Business Analysts              | Cost-efficient, balanced models  |
| Developers                     | Low latency, good speed          |
| Researchers                    | Maximum intelligence & context   |
| General Users                  | Balanced, mid-tier models        |

---

## ğŸ“Œ Key Insights

* ğŸ’¡ There is **no universally best model**
* ğŸ’° Higher price â‰  higher intelligence
* âš¡ Speed â‰  responsiveness
* ğŸ“‰ Diminishing returns exist in premium tiers
* ğŸ¯ Model selection must be **use-case driven**

---

## âœ… Recommendations

* Avoid defaulting to premium models without justification
* Use **intelligence-per-dollar** for cost-sensitive decisions
* Prioritize **low latency** for real-time systems
* Choose **high speed** for batch workloads
* Treat large context windows as **specialized features**

---

## âš  Limitations

* Intelligence index methodology not disclosed
* No time-series data
* Pricing may vary by deployment or region
* Real-world performance may differ under load

---

## ğŸ“ Repository Structure

```
â”œâ”€â”€ ai_models_performance.ipynb
â”œâ”€â”€ data/
â”‚   â””â”€â”€ ai_models_performance.csv
â”œâ”€â”€ dashboards/
â”‚   â””â”€â”€ *.png
â”œâ”€â”€ README.md
```

---

## ğŸš€ How to Run

```bash
pip install pandas numpy matplotlib
```

Open and run:

```
ai_models_performance.ipynb
```


